{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.cuda import to_cpu\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import urllib.request\n",
    "\n",
    "import my_libs.network as my_net\n",
    "import my_libs.preprocess as my_process\n",
    "from my_libs.load_data import load_new_dataset\n",
    "from run_evaluation import learn_network_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/accuracy  validation/main/accuracy  main/loss   validation/main/loss  elapsed_time\n",
      "\u001b[J1           0.936508       0.9625                    0.192835    0.0926208             150.564       \n",
      "\u001b[J2           0.96371        0.97                      0.108717    0.0894009             299.423       \n",
      "Preprocess             Processing_11\n",
      "Model                            VGG\n",
      "Elapsed time                 299.423\n",
      "Validation accuracy             0.97\n",
      "batch_size                        32\n",
      "epoch                              2\n",
      "fixed_base_w                    True\n",
      "use_gpu                         True\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "setting = {\n",
    "    'epoch': 2,\n",
    "    'batch_size': 32,\n",
    "    'use_gpu': True,\n",
    "    'fixed_base_w': True\n",
    "}\n",
    "\n",
    "vgg1 = learn_network_model(my_process.Processing_11(), my_net.VGG(), setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/accuracy  validation/main/accuracy  main/loss   validation/main/loss  elapsed_time\n",
      "\u001b[J1           0.900794       0.94375                   9.82045     0.820429              147.112       \n",
      "\u001b[J2           0.953125       0.965                     0.476862    0.285522              293.962       \n",
      "Preprocess             Processing_11\n",
      "Model                          VGG_3\n",
      "Elapsed time                 293.962\n",
      "Validation accuracy            0.965\n",
      "batch_size                        32\n",
      "epoch                              2\n",
      "fixed_base_w                    True\n",
      "use_gpu                         True\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "setting = {\n",
    "    'epoch': 2,\n",
    "    'batch_size': 32,\n",
    "    'use_gpu': True,\n",
    "    'fixed_base_w': True\n",
    "}\n",
    "\n",
    "vgg2 = learn_network_model(my_process.Processing_11(), my_net.VGG_3(), setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/accuracy  validation/main/accuracy  main/loss   validation/main/loss  elapsed_time\n",
      "\u001b[J1           0.874504       0.96125                   8.19846     0.11324               150.002       \n",
      "\u001b[J2           0.944556       0.96                      0.153258    0.102175              299.649       \n",
      "Preprocess             Processing_11\n",
      "Model                          VGG_2\n",
      "Elapsed time                 299.649\n",
      "Validation accuracy             0.96\n",
      "batch_size                        32\n",
      "epoch                              2\n",
      "fixed_base_w                    True\n",
      "use_gpu                         True\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "setting = {\n",
    "    'epoch': 2,\n",
    "    'batch_size': 32,\n",
    "    'use_gpu': True,\n",
    "    'fixed_base_w': True\n",
    "}\n",
    "\n",
    "vgg3 = learn_network_model(my_process.Processing_11(), my_net.VGG_2(), setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testデータで推測してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 800, 1000)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset: tuple(path, label)\n",
    "train, valid, test = load_new_dataset('../new_dataset/dataset/data/')\n",
    "len(train), len(valid), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target_label(tuple_dataset):\n",
    "    return [tpl[1] for tpl in tuple_dataset]\n",
    "\n",
    "def model_predict(tuple_dataset, model, gpu_id=0):\n",
    "    model.to_gpu(gpu_id)\n",
    "\n",
    "    predicted = []\n",
    "    for img, label in tuple_dataset:\n",
    "        img = np.array([img])\n",
    "        img = model.xp.asarray(img)\n",
    "\n",
    "        with chainer.using_config('train', False), chainer.using_config('enable_backprp', False):\n",
    "            predict = model.predictor(img)\n",
    "\n",
    "        predict = to_cpu(predict.data)\n",
    "        predicted.append(np.argmax(predict))\n",
    "\n",
    "    model.to_cpu()\n",
    "    return predicted\n",
    "\n",
    "def evaluate_predict(target_labels, predicted):\n",
    "    print(accuracy_score(test_t, predicted))\n",
    "    print(confusion_matrix(test_t, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_process' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bfc81271ab8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcessing_11\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_process' is not defined"
     ]
    }
   ],
   "source": [
    "# transform\n",
    "preprocess = my_process.Processing_11()\n",
    "train = preprocess.transform(train)\n",
    "valid = preprocess.transform(valid)\n",
    "test = preprocess.transform(test)\n",
    "\n",
    "train_t = get_target_label(train)\n",
    "valid_t = get_target_label(valid)\n",
    "test_t = get_target_label(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7bb4db59e1cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# アンサンブル前のモデルのテストデータ精度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mevaluate_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_predict' is not defined"
     ]
    }
   ],
   "source": [
    "# アンサンブル前のモデルのテストデータ精度\n",
    "predicted = model_predict(test, vgg1)\n",
    "evaluate_predict(test_t, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble学習\n",
    "Test Time augumentaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18350080 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/local/lib/python3.5/dist-packages/PIL/TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 6. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/30 cumputed.\n",
      "2/30 cumputed.\n",
      "3/30 cumputed.\n",
      "4/30 cumputed.\n",
      "5/30 cumputed.\n",
      "6/30 cumputed.\n",
      "7/30 cumputed.\n",
      "8/30 cumputed.\n",
      "9/30 cumputed.\n",
      "10/30 cumputed.\n",
      "11/30 cumputed.\n",
      "12/30 cumputed.\n",
      "13/30 cumputed.\n",
      "14/30 cumputed.\n",
      "15/30 cumputed.\n",
      "16/30 cumputed.\n",
      "17/30 cumputed.\n",
      "18/30 cumputed.\n",
      "19/30 cumputed.\n",
      "20/30 cumputed.\n",
      "21/30 cumputed.\n",
      "22/30 cumputed.\n",
      "23/30 cumputed.\n",
      "24/30 cumputed.\n",
      "25/30 cumputed.\n",
      "26/30 cumputed.\n",
      "27/30 cumputed.\n",
      "28/30 cumputed.\n",
      "29/30 cumputed.\n",
      "30/30 cumputed.\n",
      "CPU times: user 13min 41s, sys: 3min 53s, total: 17min 34s\n",
      "Wall time: 17min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TTA_N = 30\n",
    "predict_sum = np.zeros(len(test_t))\n",
    "for i in range(TTA_N):\n",
    "    predict_sum += model_predict(test, vgg1)\n",
    "    print('%s/%s cumputed.' % (i+1, TTA_N))\n",
    "\n",
    "predict_tta = (predict_sum/TTA_N > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n",
      "[[468  32]\n",
      " [  8 492]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_predict(test_t, predict_tta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18350080 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/local/lib/python3.5/dist-packages/PIL/TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 6. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 cumputed.\n",
      "2/10 cumputed.\n",
      "3/10 cumputed.\n",
      "4/10 cumputed.\n",
      "5/10 cumputed.\n",
      "6/10 cumputed.\n",
      "7/10 cumputed.\n",
      "8/10 cumputed.\n",
      "9/10 cumputed.\n",
      "10/10 cumputed.\n",
      "0.959\n",
      "[[472  28]\n",
      " [ 13 487]]\n",
      "CPU times: user 4min 31s, sys: 1min 18s, total: 5min 50s\n",
      "Wall time: 5min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TTA_N = 10\n",
    "predict_sum = np.zeros(len(test_t))\n",
    "for i in range(TTA_N):\n",
    "    predict_sum += model_predict(test, vgg1)\n",
    "    print('%s/%s cumputed.' % (i+1, TTA_N))\n",
    "\n",
    "predict_tta = (predict_sum/TTA_N > 0.5).astype(int)\n",
    "evaluate_predict(test_t, predict_tta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random seed average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_stacked_predict(tuple_dataset, model_list):\n",
    "    predicts = pd.DataFrame()\n",
    "    for i, model in enumerate(model_list):\n",
    "        predicts['model_%s' % i] = model_predict(tuple_dataset, model)\n",
    "    return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18350080 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/local/lib/python3.5/dist-packages/PIL/TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 6. \n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "model_list = [vgg1, vgg1, vgg1, vgg1, vgg1]\n",
    "train_predicts = make_stacked_predict(test, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953\n",
      "[[466  34]\n",
      " [ 13 487]]\n"
     ]
    }
   ],
   "source": [
    "avg_predict = (predict_df.mean(axis=1) > 0.5).astype(int)\n",
    "evaluate_predict(test_t, avg_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18350080 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/local/lib/python3.5/dist-packages/PIL/TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 6. \n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_list = [vgg1, vgg1, vgg1, vgg1, vgg1]\n",
    "\n",
    "train_predicts_x = make_stacked_predict(train, model_list)\n",
    "valid_predicts_x = make_stacked_predict(valid, model_list)\n",
    "test_predicts_x = make_stacked_predict(test, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9825\n",
      "0.958\n"
     ]
    }
   ],
   "source": [
    "# stackedモデルの学習\n",
    "stk_model = LinearRegression()\n",
    "stk_model.fit(train_predicts_x, train_t)\n",
    "\n",
    "# stackedモデルの予測(valid)\n",
    "valid_stk_pred = (stk_model.predict(valid_predicts_x) > 0.5).astype(int)\n",
    "print(accuracy_score(valid_t, valid_stk_pred))\n",
    "\n",
    "# stackedモデルの予測(test)\n",
    "test_stk_pred = (stk_model.predict(test_predicts_x) > 0.5).astype(int)\n",
    "print(accuracy_score(test_t, test_stk_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3モデルStacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18350080 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/usr/local/lib/python3.5/dist-packages/PIL/TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 6. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 7s, sys: 1min 29s, total: 6min 36s\n",
      "Wall time: 6min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_list = [vgg1, vgg2, vgg3]\n",
    "\n",
    "train_predicts_x = make_stacked_predict(train, model_list)\n",
    "valid_predicts_x = make_stacked_predict(valid, model_list)\n",
    "test_predicts_x = make_stacked_predict(test, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "0.937\n"
     ]
    }
   ],
   "source": [
    "# stackedモデルの学習\n",
    "stk_model = RandomForestRegressor()\n",
    "stk_model.fit(train_predicts_x, train_t)\n",
    "\n",
    "# stackedモデルの予測(valid)\n",
    "valid_stk_pred = (stk_model.predict(valid_predicts_x) > 0.5).astype(int)\n",
    "print(accuracy_score(valid_t, valid_stk_pred))\n",
    "\n",
    "# stackedモデルの予測(test)\n",
    "test_stk_pred = (stk_model.predict(test_predicts_x) > 0.5).astype(int)\n",
    "print(accuracy_score(test_t, test_stk_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.937\n",
      "[[481  19]\n",
      " [ 44 456]]\n"
     ]
    }
   ],
   "source": [
    "# Test Average\n",
    "avg_predict = (test_predicts_x.mean(axis=1) > 0.5).astype(int)\n",
    "evaluate_predict(test_t, avg_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
